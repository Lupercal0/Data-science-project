{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 131,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import seaborn as sns\n",
    "import pandas as pd\n",
    "import math\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense\n",
    "from keras.layers import LSTM\n",
    "from keras.layers import Dropout\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.metrics import mean_squared_error"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Date</th>\n",
       "      <th>Alabama</th>\n",
       "      <th>Alaska</th>\n",
       "      <th>Arizona</th>\n",
       "      <th>Arkansas</th>\n",
       "      <th>California</th>\n",
       "      <th>Colorado</th>\n",
       "      <th>Connecticut</th>\n",
       "      <th>Delaware</th>\n",
       "      <th>District of Columbia</th>\n",
       "      <th>...</th>\n",
       "      <th>Tennessee</th>\n",
       "      <th>Texas</th>\n",
       "      <th>Utah</th>\n",
       "      <th>Vermont</th>\n",
       "      <th>Virginia</th>\n",
       "      <th>Washington</th>\n",
       "      <th>West Virginia</th>\n",
       "      <th>Wisconsin</th>\n",
       "      <th>Wyoming</th>\n",
       "      <th>National</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>Jan-76</td>\n",
       "      <td>7.5</td>\n",
       "      <td>9.3</td>\n",
       "      <td>11.5</td>\n",
       "      <td>8.8</td>\n",
       "      <td>10.4</td>\n",
       "      <td>7.1</td>\n",
       "      <td>10.9</td>\n",
       "      <td>8.7</td>\n",
       "      <td>9.2</td>\n",
       "      <td>...</td>\n",
       "      <td>6.8</td>\n",
       "      <td>6.3</td>\n",
       "      <td>6.8</td>\n",
       "      <td>10.0</td>\n",
       "      <td>7.1</td>\n",
       "      <td>10.4</td>\n",
       "      <td>9.1</td>\n",
       "      <td>6.8</td>\n",
       "      <td>5.9</td>\n",
       "      <td>8.8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>Feb-76</td>\n",
       "      <td>7.7</td>\n",
       "      <td>9.7</td>\n",
       "      <td>10.6</td>\n",
       "      <td>8.6</td>\n",
       "      <td>10.1</td>\n",
       "      <td>6.6</td>\n",
       "      <td>10.8</td>\n",
       "      <td>8.6</td>\n",
       "      <td>9.3</td>\n",
       "      <td>...</td>\n",
       "      <td>6.7</td>\n",
       "      <td>6.2</td>\n",
       "      <td>7.3</td>\n",
       "      <td>9.7</td>\n",
       "      <td>7.0</td>\n",
       "      <td>10.2</td>\n",
       "      <td>9.0</td>\n",
       "      <td>7.6</td>\n",
       "      <td>5.0</td>\n",
       "      <td>8.7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>Mar-76</td>\n",
       "      <td>6.3</td>\n",
       "      <td>8.7</td>\n",
       "      <td>9.8</td>\n",
       "      <td>7.5</td>\n",
       "      <td>9.4</td>\n",
       "      <td>6.9</td>\n",
       "      <td>9.9</td>\n",
       "      <td>8.3</td>\n",
       "      <td>8.6</td>\n",
       "      <td>...</td>\n",
       "      <td>6.1</td>\n",
       "      <td>5.9</td>\n",
       "      <td>6.4</td>\n",
       "      <td>9.4</td>\n",
       "      <td>6.4</td>\n",
       "      <td>9.5</td>\n",
       "      <td>8.3</td>\n",
       "      <td>6.5</td>\n",
       "      <td>4.7</td>\n",
       "      <td>8.1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>Apr-76</td>\n",
       "      <td>5.7</td>\n",
       "      <td>7.5</td>\n",
       "      <td>9.2</td>\n",
       "      <td>6.7</td>\n",
       "      <td>8.8</td>\n",
       "      <td>5.2</td>\n",
       "      <td>9.4</td>\n",
       "      <td>7.9</td>\n",
       "      <td>7.7</td>\n",
       "      <td>...</td>\n",
       "      <td>5.5</td>\n",
       "      <td>5.2</td>\n",
       "      <td>5.5</td>\n",
       "      <td>9.0</td>\n",
       "      <td>5.5</td>\n",
       "      <td>8.4</td>\n",
       "      <td>7.6</td>\n",
       "      <td>5.5</td>\n",
       "      <td>4.1</td>\n",
       "      <td>7.4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>May-76</td>\n",
       "      <td>5.2</td>\n",
       "      <td>6.5</td>\n",
       "      <td>8.4</td>\n",
       "      <td>6.2</td>\n",
       "      <td>7.9</td>\n",
       "      <td>4.5</td>\n",
       "      <td>8.8</td>\n",
       "      <td>7.5</td>\n",
       "      <td>7.6</td>\n",
       "      <td>...</td>\n",
       "      <td>5.0</td>\n",
       "      <td>5.1</td>\n",
       "      <td>4.7</td>\n",
       "      <td>8.0</td>\n",
       "      <td>5.3</td>\n",
       "      <td>7.5</td>\n",
       "      <td>6.8</td>\n",
       "      <td>4.8</td>\n",
       "      <td>3.4</td>\n",
       "      <td>6.8</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 53 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     Date  Alabama  Alaska  Arizona  Arkansas  California  Colorado  \\\n",
       "0  Jan-76      7.5     9.3     11.5       8.8        10.4       7.1   \n",
       "1  Feb-76      7.7     9.7     10.6       8.6        10.1       6.6   \n",
       "2  Mar-76      6.3     8.7      9.8       7.5         9.4       6.9   \n",
       "3  Apr-76      5.7     7.5      9.2       6.7         8.8       5.2   \n",
       "4  May-76      5.2     6.5      8.4       6.2         7.9       4.5   \n",
       "\n",
       "   Connecticut  Delaware  District of Columbia  ...  Tennessee  Texas  Utah  \\\n",
       "0         10.9       8.7                   9.2  ...        6.8    6.3   6.8   \n",
       "1         10.8       8.6                   9.3  ...        6.7    6.2   7.3   \n",
       "2          9.9       8.3                   8.6  ...        6.1    5.9   6.4   \n",
       "3          9.4       7.9                   7.7  ...        5.5    5.2   5.5   \n",
       "4          8.8       7.5                   7.6  ...        5.0    5.1   4.7   \n",
       "\n",
       "   Vermont  Virginia  Washington  West Virginia  Wisconsin  Wyoming  National  \n",
       "0     10.0       7.1        10.4            9.1        6.8      5.9       8.8  \n",
       "1      9.7       7.0        10.2            9.0        7.6      5.0       8.7  \n",
       "2      9.4       6.4         9.5            8.3        6.5      4.7       8.1  \n",
       "3      9.0       5.5         8.4            7.6        5.5      4.1       7.4  \n",
       "4      8.0       5.3         7.5            6.8        4.8      3.4       6.8  \n",
       "\n",
       "[5 rows x 53 columns]"
      ]
     },
     "execution_count": 132,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_csv('USA_unemployment_Data.csv')\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dates = pd.to_datetime(df['Date'], format=\"%b-%y\", errors=\"coerce\").fillna(pd.to_datetime(df['Date'], format=\"%y-%b\", errors=\"coerce\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 149,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 7.5,  7.7,  6.3,  5.7,  5.2,  7.4,  7.2,  7.1,  6.7,  6.6,  6.7,\n",
       "        6.6,  7.7,  8.4,  7.4,  6.7,  6.5,  8.4,  7.7,  7.6,  6.7,  6.4,\n",
       "        6.4,  6. ,  7. ,  7. ,  6.2,  5.5,  5.3,  7. ,  6.7,  6.7,  6.5,\n",
       "        6.2,  6.5,  6.7,  7. ,  7.6,  6.9,  6.5,  6.3,  8.1,  7.4,  7.9,\n",
       "        7.2,  7.3,  7.2,  7.1,  8.1,  8.2,  7.6,  7.7,  8.1,  9.6,  9.7,\n",
       "        9.8,  9.1,  9.3,  9.3,  9.1, 10.3, 10.6,  9.7,  9.3,  9.5, 11. ,\n",
       "       10.6, 10.9, 11. , 11.5, 11.8, 12.3, 13.3, 13.7, 13.1, 12.9, 12.9,\n",
       "       14.4, 14.4, 14.5, 14.2, 14.5, 14.8, 14.8, 15.6, 15.6, 14.5, 13.8,\n",
       "       13.5, 14.7, 13.7, 13.9, 13.3, 12.8, 12.3, 12.1, 12.8, 12.8, 11.8,\n",
       "       11.3, 10.6, 11.6, 11.6, 11.5, 10.8, 10.5, 10. , 10.1, 10.9, 10.6,\n",
       "        9.9,  9.2,  9. , 10.1,  9.6,  9.4,  9.1,  9.1,  8.9,  9. ,  9.6,\n",
       "       10.3,  9.8,  9.3,  9.2, 10.3,  9.6,  9.6,  9.5,  9.4,  9.3,  8.8,\n",
       "        9.8,  9.7,  8.8,  7.9,  7.8,  8.4,  8. ,  8. ,  7.6,  7.6,  7.4,\n",
       "        7.2,  7.9,  8. ,  7.2,  6.7,  6.8,  7.6,  7.3,  7.5,  7.2,  7. ,\n",
       "        7.2,  7. ,  7.9,  7.5,  6.8,  6.7,  6.6,  7.7,  7.2,  7.1,  6.8,\n",
       "        6.6,  6.6,  6.4,  7.1,  7.4,  6.7,  6.3,  6.2,  7. ,  6.9,  7.1,\n",
       "        6.9,  6.7,  6.7,  6.8,  7.6,  8. ,  7.4,  6.7,  7. ,  8. ,  7.5,\n",
       "        7.5,  7. ,  6.9,  7. ,  7.2,  8. ,  8.3,  7.6,  7. ,  7.1,  8.3,\n",
       "        7.9,  7.7,  7.2,  7. ,  7.1,  7.1,  8.1,  8.1,  7.4,  6.9,  6.9,\n",
       "        7.9,  7.7,  7.3,  6.8,  6.7,  6.5,  6.3,  7.4,  7.1,  6.5,  5.8,\n",
       "        5.6,  6.6,  6.4,  6.3,  5.8,  5.7,  5.6,  5.4,  6.5,  6.2,  5.8,\n",
       "        5.6,  5.6,  6.5,  6.2,  6.1,  5.8,  5.5,  5.3,  5.2,  5.8,  5.8,\n",
       "        5.4,  4.9,  5. ,  5.6,  5.5,  5.1,  5. ,  4.9,  4.9,  4.7,  5.6,\n",
       "        5.5,  5.1,  4.6,  4.5,  5.5,  5.2,  5.2,  4.9,  4.6,  4.3,  4.2,\n",
       "        4.9,  4.7,  4.5,  3.7,  3.9,  5. ,  4.8,  4.7,  4.5,  4.5,  4.3,\n",
       "        4.1,  4.9,  5. ,  4.5,  4.3,  4.3,  5.2,  5.1,  5. ,  4.8,  4.6,\n",
       "        4.5,  4.4,  5.1,  5. ,  4.6,  4. ,  4.2,  4.9,  4.9,  5. ,  4.5,\n",
       "        4.5,  4.4,  4.3,  5.3,  5.1,  4.9,  4.4,  4.3,  5.4,  5.2,  5.6,\n",
       "        5.3,  5.5,  5.7,  5.6,  6.4,  6.3,  6. ,  5.4,  5.4,  6.3,  6.2,\n",
       "        6.2,  5.7,  5.6,  5.8,  5.8,  6.4,  6.2,  5.8,  5.4,  5.6,  6.7,\n",
       "        6.2,  6.3,  5.9,  5.8,  5.9,  5.6,  6.4,  6.1,  6. ,  5.2,  5.3,\n",
       "        6.1,  5.8,  5.7,  5.3,  5.3,  5. ,  4.9,  5.4,  5.3,  4.6,  4. ,\n",
       "        4. ,  4.8,  4.5,  4.3,  4.3,  4.2,  4. ,  3.9,  4.5,  4.5,  4. ,\n",
       "        3.6,  3.6,  4.4,  4.4,  4.2,  3.8,  3.6,  3.6,  3.7,  4.3,  4.2,\n",
       "        3.8,  3.4,  3.5,  4.4,  4.4,  4.3,  4.1,  3.9,  4. ,  4.3,  5.1,\n",
       "        5. ,  4.9,  4.3,  5. ,  6. ,  6.2,  6.4,  6.3,  6.6,  6.9,  7.5,\n",
       "        9. ,  9.5,  9.4,  8.9,  9.5, 10.6, 10.7, 10.8, 10.7, 10.9, 10.6,\n",
       "       10.8, 11.7, 11.4, 11. , 10.1,  9.9, 10.4, 10.3, 10.2,  9.9,  9.9,\n",
       "       10. ,  9.9, 10.7, 10.3,  9.8,  9.2,  9.3, 10.3, 10.1,  9.8,  9.5,\n",
       "        9. ,  8.5,  8.4,  9. ,  8.9,  8.4,  7.6,  7.9,  8.9,  8.8,  8.4,\n",
       "        7.7,  7.6,  7.2,  7.4,  8.4,  8. ,  7.3,  6.6,  6.9,  7.8,  7.6,\n",
       "        7.5,  7.2,  7.1,  6.8,  6.8,  7.6,  7.6,  7.2,  6.2,  6.5,  7.2,\n",
       "        7.3,  7. ,  6.4,  6.2,  6. ,  5.8,  6.6,  6.3,  6. ,  5.5,  6. ,\n",
       "        6.6,  6.6,  6.3,  6. ,  6. ,  5.9,  5.9,  6.5,  6.3,  6.1,  5.4,\n",
       "        5.4,  6.3,  6.1,  6. ,  5.9,  5.9,  5.3,  5.4,  6. ,  5.6,  5. ,\n",
       "        4.3,  4.1,  4.9,  4.7,  4.5])"
      ]
     },
     "execution_count": 149,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ar=np.array(df_for_training)\n",
    "ar[:,0][0:500]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 143,
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "'(slice(None, None, None), 0)' is an invalid key",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-143-68f947f37f66>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      3\u001b[0m \u001b[0mscaler\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mStandardScaler\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      4\u001b[0m \u001b[0mscaler\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mscaler\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdf_for_training\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 5\u001b[1;33m \u001b[0mdf_for_training_scaled\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mscaler\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtransform\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdf_for_training\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;36m540\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32mF:\\UNIMELB\\Elements_of_data_processing\\Anaconda\\lib\\site-packages\\pandas\\core\\frame.py\u001b[0m in \u001b[0;36m__getitem__\u001b[1;34m(self, key)\u001b[0m\n\u001b[0;32m   2978\u001b[0m             \u001b[1;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcolumns\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mnlevels\u001b[0m \u001b[1;33m>\u001b[0m \u001b[1;36m1\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2979\u001b[0m                 \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_getitem_multilevel\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 2980\u001b[1;33m             \u001b[0mindexer\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcolumns\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mget_loc\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   2981\u001b[0m             \u001b[1;32mif\u001b[0m \u001b[0mis_integer\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mindexer\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2982\u001b[0m                 \u001b[0mindexer\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[0mindexer\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mF:\\UNIMELB\\Elements_of_data_processing\\Anaconda\\lib\\site-packages\\pandas\\core\\indexes\\base.py\u001b[0m in \u001b[0;36mget_loc\u001b[1;34m(self, key, method, tolerance)\u001b[0m\n\u001b[0;32m   2895\u001b[0m                 )\n\u001b[0;32m   2896\u001b[0m             \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 2897\u001b[1;33m                 \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_engine\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mget_loc\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   2898\u001b[0m             \u001b[1;32mexcept\u001b[0m \u001b[0mKeyError\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2899\u001b[0m                 \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_engine\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mget_loc\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_maybe_cast_indexer\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mpandas\\_libs\\index.pyx\u001b[0m in \u001b[0;36mpandas._libs.index.IndexEngine.get_loc\u001b[1;34m()\u001b[0m\n",
      "\u001b[1;32mpandas\\_libs\\index.pyx\u001b[0m in \u001b[0;36mpandas._libs.index.IndexEngine.get_loc\u001b[1;34m()\u001b[0m\n",
      "\u001b[1;31mTypeError\u001b[0m: '(slice(None, None, None), 0)' is an invalid key"
     ]
    }
   ],
   "source": [
    "cols = list(df)[1:]\n",
    "df_for_training = df[cols].astype(float)\n",
    "scaler = StandardScaler()\n",
    "scaler = scaler.fit(df_for_training)\n",
    "df_for_training_scaled = scaler.transform(df_for_training[:,0][0:540])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 135,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "trainX shape == (552, 3, 52).\n",
      "trainY shape == (552, 1).\n"
     ]
    }
   ],
   "source": [
    "trainX = []\n",
    "trainY = []\n",
    "n_future = 1\n",
    "n_past = 3\n",
    "\n",
    "for i in range (n_past, len(df_for_training_scaled)- n_future +1):\n",
    "    trainX.append(df_for_training_scaled[i - n_past:i, 0:df_for_training.shape[1]])\n",
    "    trainY.append(df_for_training_scaled[i + n_future - 1:i + n_future, 0])\n",
    "\n",
    "trainX, trainY = np.array(trainX), np.array(trainY)\n",
    "print('trainX shape == {}.'.format(trainX.shape))\n",
    "print('trainY shape == {}.'.format(trainY.shape))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_6\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " lstm_12 (LSTM)              (None, 3, 64)             29952     \n",
      "                                                                 \n",
      " lstm_13 (LSTM)              (None, 3, 32)             12416     \n",
      "                                                                 \n",
      " dropout_5 (Dropout)         (None, 3, 32)             0         \n",
      "                                                                 \n",
      " dense_5 (Dense)             (None, 3, 1)              33        \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 42,401\n",
      "Trainable params: 42,401\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model = Sequential()\n",
    "model.add(LSTM(64, activation = 'relu', input_shape=(trainX.shape[1], trainX.shape[2]), return_sequences=True))\n",
    "model.add(LSTM(32, activation = 'relu', return_sequences=True))\n",
    "model.add(Dropout(0.2))\n",
    "model.add(Dense(trainY.shape[1]))\n",
    "\n",
    "model.compile(optimizer = 'adam', loss = 'mse')\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 137,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "31/31 [==============================] - 2s 14ms/step - loss: 0.5398 - val_loss: 0.9114\n",
      "Epoch 2/10\n",
      "31/31 [==============================] - 0s 4ms/step - loss: 0.2870 - val_loss: 0.9054\n",
      "Epoch 3/10\n",
      "31/31 [==============================] - 0s 4ms/step - loss: 0.2111 - val_loss: 0.9907\n",
      "Epoch 4/10\n",
      "31/31 [==============================] - 0s 4ms/step - loss: 0.1952 - val_loss: 0.9412\n",
      "Epoch 5/10\n",
      "31/31 [==============================] - 0s 4ms/step - loss: 0.1485 - val_loss: 0.8023\n",
      "Epoch 6/10\n",
      "31/31 [==============================] - 0s 4ms/step - loss: 0.1332 - val_loss: 0.8105\n",
      "Epoch 7/10\n",
      "31/31 [==============================] - 0s 4ms/step - loss: 0.1116 - val_loss: 0.7595\n",
      "Epoch 8/10\n",
      "31/31 [==============================] - 0s 4ms/step - loss: 0.1009 - val_loss: 0.8949\n",
      "Epoch 9/10\n",
      "31/31 [==============================] - 0s 4ms/step - loss: 0.1000 - val_loss: 0.7065\n",
      "Epoch 10/10\n",
      "31/31 [==============================] - 0s 4ms/step - loss: 0.0902 - val_loss: 0.7605\n"
     ]
    }
   ],
   "source": [
    "history = model.fit(trainX, trainY, epochs=10, batch_size=16, validation_split=0.1, verbose=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 138,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:6 out of the last 8 calls to <function Model.make_predict_function.<locals>.predict_function at 0x0000020C05B308B8> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has reduce_retracing=True option that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "1/1 [==============================] - 0s 264ms/step\n"
     ]
    }
   ],
   "source": [
    "n_future=12\n",
    "forcast_period_dates = pd.date_range(list(train_dates)[-1], periods=n_future,freq='1m' ).tolist()\n",
    "forcast = model.predict(trainX[-n_future:])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 139,
   "metadata": {},
   "outputs": [],
   "source": [
    "forcast_copies = np.repeat(forcast, df_for_training.shape[1], axis=-1)\n",
    "y_pred_future = scaler.inverse_transform(forcast_copies)[:,0]\n",
    "\n",
    "forcast_dates = []\n",
    "for time_i in forcast_period_dates:\n",
    "    forcast_dates.append(time_i.date())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 140,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[datetime.date(2022, 3, 31) datetime.date(2022, 4, 30)\n",
      " datetime.date(2022, 5, 31) datetime.date(2022, 6, 30)\n",
      " datetime.date(2022, 7, 31) datetime.date(2022, 8, 31)\n",
      " datetime.date(2022, 9, 30) datetime.date(2022, 10, 31)\n",
      " datetime.date(2022, 11, 30) datetime.date(2022, 12, 31)\n",
      " datetime.date(2023, 1, 31) datetime.date(2023, 2, 28)]\n"
     ]
    }
   ],
   "source": [
    "print(np.array(forcast_dates))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 141,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "F:\\UNIMELB\\Elements_of_data_processing\\Anaconda\\lib\\site-packages\\ipykernel_launcher.py:5: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  \"\"\"\n"
     ]
    }
   ],
   "source": [
    "df_forcast = pd.DataFrame({'Date':np.array(forcast_dates), 'Alabama':y_pred_future[:,0]})\n",
    "df_forcast['Date']=pd.to_datetime(df_forcast['Date'])\n",
    "\n",
    "original = df[['Date', 'Alabama']]\n",
    "original['Date'] = pd.to_datetime(df['Date'], format=\"%b-%y\", errors=\"coerce\").fillna(pd.to_datetime(df['Date'], format=\"%y-%b\", errors=\"coerce\"))\n",
    "# sns.lineplot(df_forcast['Date'], original['Alabama'])\n",
    "# sns.lineplot(df_forcast['Date'], df_forcast['Alabama'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 142,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Date</th>\n",
       "      <th>Alabama</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>2022-03-31</td>\n",
       "      <td>6.812989</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>2022-04-30</td>\n",
       "      <td>6.687788</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>2022-05-31</td>\n",
       "      <td>6.529402</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>2022-06-30</td>\n",
       "      <td>6.322900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>2022-07-31</td>\n",
       "      <td>6.209394</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5</td>\n",
       "      <td>2022-08-31</td>\n",
       "      <td>6.546832</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>6</td>\n",
       "      <td>2022-09-30</td>\n",
       "      <td>6.122738</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>7</td>\n",
       "      <td>2022-10-31</td>\n",
       "      <td>5.773018</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>8</td>\n",
       "      <td>2022-11-30</td>\n",
       "      <td>5.188392</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>9</td>\n",
       "      <td>2022-12-31</td>\n",
       "      <td>4.747318</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>10</td>\n",
       "      <td>2023-01-31</td>\n",
       "      <td>4.433885</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>11</td>\n",
       "      <td>2023-02-28</td>\n",
       "      <td>4.170106</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         Date   Alabama\n",
       "0  2022-03-31  6.812989\n",
       "1  2022-04-30  6.687788\n",
       "2  2022-05-31  6.529402\n",
       "3  2022-06-30  6.322900\n",
       "4  2022-07-31  6.209394\n",
       "5  2022-08-31  6.546832\n",
       "6  2022-09-30  6.122738\n",
       "7  2022-10-31  5.773018\n",
       "8  2022-11-30  5.188392\n",
       "9  2022-12-31  4.747318\n",
       "10 2023-01-31  4.433885\n",
       "11 2023-02-28  4.170106"
      ]
     },
     "execution_count": 142,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_forcast"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
